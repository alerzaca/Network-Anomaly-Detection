{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 20:10:03.679103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 20:10:03.692779: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 20:10:03.696862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 20:10:03.708154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 20:10:04.488805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = pd.read_parquet('./Local/2017_Clean/Combined.parquet')\n",
    "data_f1 = pd.read_parquet('./Local/2017_Final/Combined_1.parquet')\n",
    "data_f2 = pd.read_parquet('./Local/2017_Final/Combined_2.parquet')\n",
    "\n",
    "datasets = {'Clean data': data_c, 'Final data 1': data_f1, 'Final data 2': data_f2}\n",
    "autoencoders = {}\n",
    "reconstruction_errors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    if 'Label' in df.columns:\n",
    "        label_col = 'Label'\n",
    "    elif ' Label' in df.columns:\n",
    "        label_col = ' Label'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame does not contain a label column\")\n",
    "    \n",
    "    df[label_col] = label_encoder.fit_transform(df[label_col])\n",
    "    \n",
    "    X = df.drop(label_col, axis=1)\n",
    "    y = df[label_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "processed_datasets = {name: preprocess_data(df) for name, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 100\n",
    "encoding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_dim, encoding_dim):\n",
    "    # Encoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    \n",
    "    # Decoder\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    \n",
    "    # Autoencoder\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mse')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "def train_autoencoder(autoencoder, X_train, X_test, epochs=epochs, batch_size=batch_size):\n",
    "    # Train the autoencoder\n",
    "    history = autoencoder.fit(X_train, X_train,\n",
    "                              epochs=epochs,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(X_test, X_test),\n",
    "                              verbose=1)\n",
    "    return history\n",
    "\n",
    "def evaluate_autoencoder(autoencoder, X_test):\n",
    "    # Get the reconstruction errors\n",
    "    X_test_pred = autoencoder.predict(X_test)\n",
    "    reconstruction_errors = np.mean(np.square(X_test - X_test_pred), axis=1)\n",
    "    return reconstruction_errors\n",
    "\n",
    "def autoencoder_anomaly_detection(X_train, X_test, encoding_dim=encoding_dim, epochs=epochs, batch_size=batch_size):\n",
    "    input_dim = X_train.shape[1]\n",
    "    autoencoder = build_autoencoder(input_dim, encoding_dim)\n",
    "    train_autoencoder(autoencoder, X_train, X_test, epochs, batch_size)\n",
    "    reconstruction_errors = evaluate_autoencoder(autoencoder, X_test)\n",
    "    return autoencoder, reconstruction_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 749us/step - loss: 0.6925 - val_loss: 0.7708\n",
      "Epoch 2/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 727us/step - loss: 0.6623 - val_loss: 0.7700\n",
      "Epoch 3/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 709us/step - loss: 0.6570 - val_loss: 0.7698\n",
      "Epoch 4/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6021 - val_loss: 0.7698\n",
      "Epoch 5/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6465 - val_loss: 0.7698\n",
      "Epoch 6/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 717us/step - loss: 0.7241 - val_loss: 0.7697\n",
      "Epoch 7/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.6149 - val_loss: 0.7697\n",
      "Epoch 8/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6638 - val_loss: 0.7697\n",
      "Epoch 9/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6362 - val_loss: 0.7697\n",
      "Epoch 10/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 707us/step - loss: 0.6552 - val_loss: 0.7697\n",
      "Epoch 11/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6295 - val_loss: 0.7697\n",
      "Epoch 12/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.5727 - val_loss: 0.7697\n",
      "Epoch 13/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 717us/step - loss: 0.5910 - val_loss: 0.7697\n",
      "Epoch 14/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708us/step - loss: 0.6730 - val_loss: 0.7696\n",
      "Epoch 15/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.6274 - val_loss: 0.7696\n",
      "Epoch 16/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701us/step - loss: 0.5727 - val_loss: 0.7696\n",
      "Epoch 17/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 712us/step - loss: 0.6569 - val_loss: 0.7696\n",
      "Epoch 18/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6788 - val_loss: 0.7696\n",
      "Epoch 19/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701us/step - loss: 0.6368 - val_loss: 0.7696\n",
      "Epoch 20/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.5783 - val_loss: 0.7694\n",
      "Epoch 21/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 704us/step - loss: 0.6340 - val_loss: 0.7694\n",
      "Epoch 22/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 721us/step - loss: 0.7187 - val_loss: 0.7694\n",
      "Epoch 23/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701us/step - loss: 0.6645 - val_loss: 0.7694\n",
      "Epoch 24/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6549 - val_loss: 0.7694\n",
      "Epoch 25/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6611 - val_loss: 0.7693\n",
      "Epoch 26/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 712us/step - loss: 0.6832 - val_loss: 0.7694\n",
      "Epoch 27/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.5960 - val_loss: 0.7694\n",
      "Epoch 28/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 709us/step - loss: 0.6239 - val_loss: 0.7694\n",
      "Epoch 29/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6543 - val_loss: 0.7693\n",
      "Epoch 30/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 707us/step - loss: 0.6455 - val_loss: 0.7693\n",
      "Epoch 31/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708us/step - loss: 0.6361 - val_loss: 0.7693\n",
      "Epoch 32/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6369 - val_loss: 0.7693\n",
      "Epoch 33/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 718us/step - loss: 0.6658 - val_loss: 0.7694\n",
      "Epoch 34/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 704us/step - loss: 0.6602 - val_loss: 0.7693\n",
      "Epoch 35/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 728us/step - loss: 0.5901 - val_loss: 0.7693\n",
      "Epoch 36/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.7462 - val_loss: 0.7693\n",
      "Epoch 37/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6304 - val_loss: 0.7693\n",
      "Epoch 38/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 721us/step - loss: 0.6537 - val_loss: 0.7693\n",
      "Epoch 39/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 707us/step - loss: 0.6588 - val_loss: 0.7693\n",
      "Epoch 40/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6507 - val_loss: 0.7693\n",
      "Epoch 41/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702us/step - loss: 0.6300 - val_loss: 0.7693\n",
      "Epoch 42/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6083 - val_loss: 0.7693\n",
      "Epoch 43/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6353 - val_loss: 0.7693\n",
      "Epoch 44/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 709us/step - loss: 0.6170 - val_loss: 0.7693\n",
      "Epoch 45/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 712us/step - loss: 0.7040 - val_loss: 0.7693\n",
      "Epoch 46/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6192 - val_loss: 0.7693\n",
      "Epoch 47/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 723us/step - loss: 0.6080 - val_loss: 0.7693\n",
      "Epoch 48/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702us/step - loss: 0.6161 - val_loss: 0.7693\n",
      "Epoch 49/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6123 - val_loss: 0.7693\n",
      "Epoch 50/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708us/step - loss: 0.6524 - val_loss: 0.7693\n",
      "Epoch 51/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6186 - val_loss: 0.7693\n",
      "Epoch 52/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701us/step - loss: 0.6717 - val_loss: 0.7693\n",
      "Epoch 53/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 709us/step - loss: 0.6718 - val_loss: 0.7693\n",
      "Epoch 54/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 717us/step - loss: 0.6785 - val_loss: 0.7693\n",
      "Epoch 55/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 706us/step - loss: 0.6443 - val_loss: 0.7693\n",
      "Epoch 56/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6226 - val_loss: 0.7693\n",
      "Epoch 57/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 700us/step - loss: 0.6173 - val_loss: 0.7693\n",
      "Epoch 58/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 718us/step - loss: 0.6162 - val_loss: 0.7693\n",
      "Epoch 59/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.5982 - val_loss: 0.7693\n",
      "Epoch 60/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 706us/step - loss: 0.6108 - val_loss: 0.7693\n",
      "Epoch 61/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6490 - val_loss: 0.7693\n",
      "Epoch 62/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6437 - val_loss: 0.7693\n",
      "Epoch 63/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 701us/step - loss: 0.6561 - val_loss: 0.7693\n",
      "Epoch 64/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.7575 - val_loss: 0.7693\n",
      "Epoch 65/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702us/step - loss: 0.6372 - val_loss: 0.7693\n",
      "Epoch 66/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6321 - val_loss: 0.7693\n",
      "Epoch 67/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.6815 - val_loss: 0.7693\n",
      "Epoch 68/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708us/step - loss: 0.6409 - val_loss: 0.7693\n",
      "Epoch 69/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.6865 - val_loss: 0.7693\n",
      "Epoch 70/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6149 - val_loss: 0.7693\n",
      "Epoch 71/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 703us/step - loss: 0.6314 - val_loss: 0.7693\n",
      "Epoch 72/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6661 - val_loss: 0.7693\n",
      "Epoch 73/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 719us/step - loss: 0.6151 - val_loss: 0.7693\n",
      "Epoch 74/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 699us/step - loss: 0.6328 - val_loss: 0.7693\n",
      "Epoch 75/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6490 - val_loss: 0.7693\n",
      "Epoch 76/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6358 - val_loss: 0.7693\n",
      "Epoch 77/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6706 - val_loss: 0.7693\n",
      "Epoch 78/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6712 - val_loss: 0.7693\n",
      "Epoch 79/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6636 - val_loss: 0.7693\n",
      "Epoch 80/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.7145 - val_loss: 0.7693\n",
      "Epoch 81/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702us/step - loss: 0.7166 - val_loss: 0.7693\n",
      "Epoch 82/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 712us/step - loss: 0.6355 - val_loss: 0.7693\n",
      "Epoch 83/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6425 - val_loss: 0.7693\n",
      "Epoch 84/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6336 - val_loss: 0.7693\n",
      "Epoch 85/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702us/step - loss: 0.7287 - val_loss: 0.7693\n",
      "Epoch 86/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 718us/step - loss: 0.6803 - val_loss: 0.7693\n",
      "Epoch 87/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 713us/step - loss: 0.5971 - val_loss: 0.7693\n",
      "Epoch 88/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 716us/step - loss: 0.6466 - val_loss: 0.7693\n",
      "Epoch 89/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 705us/step - loss: 0.6464 - val_loss: 0.7693\n",
      "Epoch 90/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6585 - val_loss: 0.7693\n",
      "Epoch 91/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6148 - val_loss: 0.7693\n",
      "Epoch 92/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6024 - val_loss: 0.7693\n",
      "Epoch 93/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 704us/step - loss: 0.6308 - val_loss: 0.7693\n",
      "Epoch 94/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.6036 - val_loss: 0.7693\n",
      "Epoch 95/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 709us/step - loss: 0.6126 - val_loss: 0.7693\n",
      "Epoch 96/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711us/step - loss: 0.6696 - val_loss: 0.7693\n",
      "Epoch 97/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708us/step - loss: 0.6317 - val_loss: 0.7693\n",
      "Epoch 98/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710us/step - loss: 0.6441 - val_loss: 0.7693\n",
      "Epoch 99/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 715us/step - loss: 0.6656 - val_loss: 0.7693\n",
      "Epoch 100/100\n",
      "\u001b[1m8040/8040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 714us/step - loss: 0.5989 - val_loss: 0.7693\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 398us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 557us/step - loss: 0.5838 - val_loss: 0.5261\n",
      "Epoch 2/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 528us/step - loss: 0.6092 - val_loss: 0.5260\n",
      "Epoch 3/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5583 - val_loss: 0.5260\n",
      "Epoch 4/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527us/step - loss: 0.7869 - val_loss: 0.5260\n",
      "Epoch 5/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527us/step - loss: 0.6459 - val_loss: 0.5260\n",
      "Epoch 6/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527us/step - loss: 0.5756 - val_loss: 0.5260\n",
      "Epoch 7/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5975 - val_loss: 0.5260\n",
      "Epoch 8/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6300 - val_loss: 0.5260\n",
      "Epoch 9/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5979 - val_loss: 0.5260\n",
      "Epoch 10/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 529us/step - loss: 0.6594 - val_loss: 0.5260\n",
      "Epoch 11/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 529us/step - loss: 0.6003 - val_loss: 0.5259\n",
      "Epoch 12/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6323 - val_loss: 0.5259\n",
      "Epoch 13/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.7119 - val_loss: 0.5259\n",
      "Epoch 14/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 528us/step - loss: 0.7022 - val_loss: 0.5259\n",
      "Epoch 15/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5740 - val_loss: 0.5259\n",
      "Epoch 16/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527us/step - loss: 0.6174 - val_loss: 0.5259\n",
      "Epoch 17/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.7264 - val_loss: 0.5259\n",
      "Epoch 18/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6192 - val_loss: 0.5259\n",
      "Epoch 19/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.5713 - val_loss: 0.5259\n",
      "Epoch 20/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6607 - val_loss: 0.5259\n",
      "Epoch 21/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5778 - val_loss: 0.5259\n",
      "Epoch 22/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6226 - val_loss: 0.5259\n",
      "Epoch 23/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6588 - val_loss: 0.5259\n",
      "Epoch 24/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6279 - val_loss: 0.5259\n",
      "Epoch 25/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6005 - val_loss: 0.5259\n",
      "Epoch 26/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6495 - val_loss: 0.5259\n",
      "Epoch 27/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6723 - val_loss: 0.5259\n",
      "Epoch 28/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 529us/step - loss: 0.6632 - val_loss: 0.5259\n",
      "Epoch 29/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5608 - val_loss: 0.5259\n",
      "Epoch 30/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6169 - val_loss: 0.5259\n",
      "Epoch 31/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6450 - val_loss: 0.5259\n",
      "Epoch 32/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6355 - val_loss: 0.5259\n",
      "Epoch 33/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.8117 - val_loss: 0.5259\n",
      "Epoch 34/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6323 - val_loss: 0.5259\n",
      "Epoch 35/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6434 - val_loss: 0.5259\n",
      "Epoch 36/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5485 - val_loss: 0.5259\n",
      "Epoch 37/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6101 - val_loss: 0.5259\n",
      "Epoch 38/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6141 - val_loss: 0.5259\n",
      "Epoch 39/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.6411 - val_loss: 0.5259\n",
      "Epoch 40/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6384 - val_loss: 0.5259\n",
      "Epoch 41/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.5960 - val_loss: 0.5259\n",
      "Epoch 42/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.5972 - val_loss: 0.5259\n",
      "Epoch 43/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.6247 - val_loss: 0.5259\n",
      "Epoch 44/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.7201 - val_loss: 0.5259\n",
      "Epoch 45/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.8020 - val_loss: 0.5259\n",
      "Epoch 46/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6435 - val_loss: 0.5259\n",
      "Epoch 47/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.7597 - val_loss: 0.5259\n",
      "Epoch 48/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.7218 - val_loss: 0.5259\n",
      "Epoch 49/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.5642 - val_loss: 0.5259\n",
      "Epoch 50/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.5780 - val_loss: 0.5259\n",
      "Epoch 51/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.7650 - val_loss: 0.5259\n",
      "Epoch 52/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6054 - val_loss: 0.5259\n",
      "Epoch 53/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6057 - val_loss: 0.5259\n",
      "Epoch 54/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.6132 - val_loss: 0.5259\n",
      "Epoch 55/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6491 - val_loss: 0.5259\n",
      "Epoch 56/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6325 - val_loss: 0.5259\n",
      "Epoch 57/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6239 - val_loss: 0.5259\n",
      "Epoch 58/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.5373 - val_loss: 0.5259\n",
      "Epoch 59/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.6409 - val_loss: 0.5259\n",
      "Epoch 60/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.6263 - val_loss: 0.5259\n",
      "Epoch 61/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5864 - val_loss: 0.5259\n",
      "Epoch 62/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 528us/step - loss: 0.6604 - val_loss: 0.5259\n",
      "Epoch 63/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6976 - val_loss: 0.5259\n",
      "Epoch 64/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6916 - val_loss: 0.5259\n",
      "Epoch 65/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.7584 - val_loss: 0.5259\n",
      "Epoch 66/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6506 - val_loss: 0.5259\n",
      "Epoch 67/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5924 - val_loss: 0.5259\n",
      "Epoch 68/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.6596 - val_loss: 0.5259\n",
      "Epoch 69/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6782 - val_loss: 0.5259\n",
      "Epoch 70/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6034 - val_loss: 0.5259\n",
      "Epoch 71/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.6522 - val_loss: 0.5259\n",
      "Epoch 72/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6361 - val_loss: 0.5259\n",
      "Epoch 73/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.5919 - val_loss: 0.5259\n",
      "Epoch 74/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.5608 - val_loss: 0.5259\n",
      "Epoch 75/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5759 - val_loss: 0.5259\n",
      "Epoch 76/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.5857 - val_loss: 0.5259\n",
      "Epoch 77/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.5950 - val_loss: 0.5259\n",
      "Epoch 78/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.7769 - val_loss: 0.5259\n",
      "Epoch 79/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.6771 - val_loss: 0.5259\n",
      "Epoch 80/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.6144 - val_loss: 0.5259\n",
      "Epoch 81/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6589 - val_loss: 0.5259\n",
      "Epoch 82/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 530us/step - loss: 0.6687 - val_loss: 0.5259\n",
      "Epoch 83/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6795 - val_loss: 0.5259\n",
      "Epoch 84/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6459 - val_loss: 0.5259\n",
      "Epoch 85/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.5660 - val_loss: 0.5259\n",
      "Epoch 86/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 531us/step - loss: 0.6118 - val_loss: 0.5259\n",
      "Epoch 87/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6347 - val_loss: 0.5259\n",
      "Epoch 88/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.5948 - val_loss: 0.5259\n",
      "Epoch 89/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.5783 - val_loss: 0.5259\n",
      "Epoch 90/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6090 - val_loss: 0.5259\n",
      "Epoch 91/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5831 - val_loss: 0.5259\n",
      "Epoch 92/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532us/step - loss: 0.5750 - val_loss: 0.5259\n",
      "Epoch 93/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6688 - val_loss: 0.5259\n",
      "Epoch 94/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6381 - val_loss: 0.5259\n",
      "Epoch 95/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.5697 - val_loss: 0.5259\n",
      "Epoch 96/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533us/step - loss: 0.6573 - val_loss: 0.5259\n",
      "Epoch 97/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 535us/step - loss: 0.6606 - val_loss: 0.5259\n",
      "Epoch 98/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536us/step - loss: 0.6817 - val_loss: 0.5259\n",
      "Epoch 99/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.5695 - val_loss: 0.5259\n",
      "Epoch 100/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534us/step - loss: 0.7032 - val_loss: 0.5259\n",
      "\u001b[1m32158/32158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 383us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 556us/step - loss: 0.8231 - val_loss: 0.5858\n",
      "Epoch 2/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.7955 - val_loss: 0.5857\n",
      "Epoch 3/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6504 - val_loss: 0.5857\n",
      "Epoch 4/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.6989 - val_loss: 0.5857\n",
      "Epoch 5/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.7008 - val_loss: 0.5857\n",
      "Epoch 6/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537us/step - loss: 0.6343 - val_loss: 0.5857\n",
      "Epoch 7/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.7223 - val_loss: 0.5857\n",
      "Epoch 8/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6428 - val_loss: 0.5857\n",
      "Epoch 9/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6818 - val_loss: 0.5857\n",
      "Epoch 10/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6400 - val_loss: 0.5857\n",
      "Epoch 11/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.7365 - val_loss: 0.5857\n",
      "Epoch 12/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6960 - val_loss: 0.5857\n",
      "Epoch 13/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6719 - val_loss: 0.5857\n",
      "Epoch 14/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.6810 - val_loss: 0.5857\n",
      "Epoch 15/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.7433 - val_loss: 0.5857\n",
      "Epoch 16/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6442 - val_loss: 0.5857\n",
      "Epoch 17/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6798 - val_loss: 0.5857\n",
      "Epoch 18/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6929 - val_loss: 0.5857\n",
      "Epoch 19/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.8233 - val_loss: 0.5857\n",
      "Epoch 20/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.8092 - val_loss: 0.5857\n",
      "Epoch 21/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6529 - val_loss: 0.5857\n",
      "Epoch 22/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6900 - val_loss: 0.5857\n",
      "Epoch 23/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.8090 - val_loss: 0.5857\n",
      "Epoch 24/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.7146 - val_loss: 0.5857\n",
      "Epoch 25/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6345 - val_loss: 0.5857\n",
      "Epoch 26/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.7069 - val_loss: 0.5857\n",
      "Epoch 27/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7179 - val_loss: 0.5857\n",
      "Epoch 28/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.6970 - val_loss: 0.5857\n",
      "Epoch 29/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 538us/step - loss: 0.7692 - val_loss: 0.5857\n",
      "Epoch 30/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7147 - val_loss: 0.5857\n",
      "Epoch 31/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6785 - val_loss: 0.5857\n",
      "Epoch 32/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6965 - val_loss: 0.5857\n",
      "Epoch 33/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 555us/step - loss: 0.7082 - val_loss: 0.5857\n",
      "Epoch 34/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.7021 - val_loss: 0.5857\n",
      "Epoch 35/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.6870 - val_loss: 0.5857\n",
      "Epoch 36/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.5911 - val_loss: 0.5857\n",
      "Epoch 37/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.8205 - val_loss: 0.5857\n",
      "Epoch 38/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.8344 - val_loss: 0.5857\n",
      "Epoch 39/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.7079 - val_loss: 0.5857\n",
      "Epoch 40/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6611 - val_loss: 0.5857\n",
      "Epoch 41/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7520 - val_loss: 0.5857\n",
      "Epoch 42/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6903 - val_loss: 0.5857\n",
      "Epoch 43/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.7632 - val_loss: 0.5857\n",
      "Epoch 44/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7752 - val_loss: 0.5857\n",
      "Epoch 45/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.8024 - val_loss: 0.5857\n",
      "Epoch 46/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.7624 - val_loss: 0.5857\n",
      "Epoch 47/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.8120 - val_loss: 0.5857\n",
      "Epoch 48/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 545us/step - loss: 0.7523 - val_loss: 0.5857\n",
      "Epoch 49/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7558 - val_loss: 0.5857\n",
      "Epoch 50/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7334 - val_loss: 0.5857\n",
      "Epoch 51/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.7831 - val_loss: 0.5857\n",
      "Epoch 52/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7110 - val_loss: 0.5857\n",
      "Epoch 53/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 553us/step - loss: 0.6583 - val_loss: 0.5857\n",
      "Epoch 54/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539us/step - loss: 0.8240 - val_loss: 0.5857\n",
      "Epoch 55/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.7363 - val_loss: 0.5857\n",
      "Epoch 56/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6419 - val_loss: 0.5857\n",
      "Epoch 57/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 545us/step - loss: 0.5932 - val_loss: 0.5857\n",
      "Epoch 58/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.8535 - val_loss: 0.5857\n",
      "Epoch 59/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.8387 - val_loss: 0.5857\n",
      "Epoch 60/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.7023 - val_loss: 0.5857\n",
      "Epoch 61/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6953 - val_loss: 0.5857\n",
      "Epoch 62/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6739 - val_loss: 0.5857\n",
      "Epoch 63/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 541us/step - loss: 0.6543 - val_loss: 0.5857\n",
      "Epoch 64/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6765 - val_loss: 0.5857\n",
      "Epoch 65/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6932 - val_loss: 0.5857\n",
      "Epoch 66/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6280 - val_loss: 0.5857\n",
      "Epoch 67/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 547us/step - loss: 0.7406 - val_loss: 0.5857\n",
      "Epoch 68/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6922 - val_loss: 0.5857\n",
      "Epoch 69/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546us/step - loss: 0.7129 - val_loss: 0.5857\n",
      "Epoch 70/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.7569 - val_loss: 0.5857\n",
      "Epoch 71/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 545us/step - loss: 0.7180 - val_loss: 0.5857\n",
      "Epoch 72/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.7048 - val_loss: 0.5857\n",
      "Epoch 73/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.7189 - val_loss: 0.5857\n",
      "Epoch 74/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6989 - val_loss: 0.5857\n",
      "Epoch 75/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 548us/step - loss: 0.6555 - val_loss: 0.5857\n",
      "Epoch 76/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 548us/step - loss: 0.6586 - val_loss: 0.5857\n",
      "Epoch 77/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6723 - val_loss: 0.5857\n",
      "Epoch 78/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 540us/step - loss: 0.6810 - val_loss: 0.5857\n",
      "Epoch 79/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6626 - val_loss: 0.5857\n",
      "Epoch 80/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546us/step - loss: 0.6205 - val_loss: 0.5857\n",
      "Epoch 81/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 545us/step - loss: 0.8635 - val_loss: 0.5857\n",
      "Epoch 82/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.7104 - val_loss: 0.5857\n",
      "Epoch 83/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6531 - val_loss: 0.5857\n",
      "Epoch 84/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.7106 - val_loss: 0.5857\n",
      "Epoch 85/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6607 - val_loss: 0.5857\n",
      "Epoch 86/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6236 - val_loss: 0.5857\n",
      "Epoch 87/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546us/step - loss: 0.7350 - val_loss: 0.5857\n",
      "Epoch 88/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6677 - val_loss: 0.5857\n",
      "Epoch 89/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6833 - val_loss: 0.5857\n",
      "Epoch 90/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.6774 - val_loss: 0.5857\n",
      "Epoch 91/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546us/step - loss: 0.7592 - val_loss: 0.5857\n",
      "Epoch 92/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543us/step - loss: 0.6481 - val_loss: 0.5857\n",
      "Epoch 93/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 548us/step - loss: 0.6911 - val_loss: 0.5857\n",
      "Epoch 94/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6094 - val_loss: 0.5857\n",
      "Epoch 95/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 545us/step - loss: 0.6411 - val_loss: 0.5857\n",
      "Epoch 96/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 547us/step - loss: 0.7237 - val_loss: 0.5857\n",
      "Epoch 97/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 542us/step - loss: 0.8593 - val_loss: 0.5857\n",
      "Epoch 98/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6402 - val_loss: 0.5857\n",
      "Epoch 99/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 547us/step - loss: 0.6344 - val_loss: 0.5857\n",
      "Epoch 100/100\n",
      "\u001b[1m16079/16079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544us/step - loss: 0.6817 - val_loss: 0.5857\n",
      "\u001b[1m32158/32158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394us/step\n"
     ]
    }
   ],
   "source": [
    "for name, (X_train, X_test, y_train, y_test) in processed_datasets.items():\n",
    "    autoencoder, errors = autoencoder_anomaly_detection(X_train, X_test)\n",
    "    autoencoders[name] = autoencoder\n",
    "    reconstruction_errors[name] = errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
