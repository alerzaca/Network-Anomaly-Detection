{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and scalling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = pd.read_parquet('./Local/2017_Clean/Combined.parquet')\n",
    "data_f1 = pd.read_parquet('./Local/2017_Final/Combined_1.parquet')\n",
    "data_f2 = pd.read_parquet('./Local/2017_Final/Combined_2.parquet')\n",
    "\n",
    "datasets = {'Clean data': data_c, 'Final data 1': data_f1, 'Final data 2': data_f2}\n",
    "matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    if 'Label' in df.columns:\n",
    "        label_col = 'Label'\n",
    "    elif ' Label' in df.columns:\n",
    "        label_col = ' Label'\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame does not contain a label column\")\n",
    "    \n",
    "    df[label_col] = label_encoder.fit_transform(df[label_col])\n",
    "    \n",
    "    X = df.drop(label_col, axis=1)\n",
    "    y = df[label_col]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "processed_datasets = {name: preprocess_data(df) for name, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Naive Bayes for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Clean data ---\n",
      "Training Accuracy :  71.08670470800423\n",
      "Validation Accuracy :  71.14792586603645\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80    429322\n",
      "           2       0.00      1.00      0.01       408\n",
      "          10       0.88      0.95      0.91     25511\n",
      "           1       0.16      0.92      0.27      2025\n",
      "           9       0.87      0.94      0.90     34698\n",
      "          12       0.14      0.67      0.24      1017\n",
      "          14       0.05      0.62      0.10      1113\n",
      "          13       0.69      1.00      0.82      1182\n",
      "           7       1.00      1.00      1.00         4\n",
      "          11       0.00      0.86      0.00         7\n",
      "           6       0.96      0.98      0.97     18185\n",
      "           5       0.37      0.92      0.53       638\n",
      "           4       0.00      0.07      0.01       289\n",
      "           3       0.01      1.00      0.01         3\n",
      "           8       0.24      0.91      0.38       126\n",
      "\n",
      "    accuracy                           0.71    514528\n",
      "   macro avg       0.43      0.83      0.46    514528\n",
      "weighted avg       0.97      0.71      0.81    514528\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.0000000e+00, 4.5112781e-02, 4.5801528e-02, ..., 3.9272622e+03,\n       4.3706865e+03, 5.8005000e+03], dtype=float32),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     11\u001b[0m gnb \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy : \u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_train, gnb\u001b[38;5;241m.\u001b[39mpredict(X_train_scaled))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _refit:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[43m_check_partial_fit_first_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:438\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[0;34m(clf, classes)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    432\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` is not the same as on last call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto partial_fit, was: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (classes, clf\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m    434\u001b[0m             )\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;66;03m# This is the first call to partial_fit\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m         clf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# nothing to do\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:104\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    102\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([0.0000000e+00, 4.5112781e-02, 4.5801528e-02, ..., 3.9272622e+03,\n       4.3706865e+03, 5.8005000e+03], dtype=float32),)"
     ]
    }
   ],
   "source": [
    "for name, data in datasets.items():\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f'--- {name} ---')\n",
    "    print('Training Accuracy : ', metrics.accuracy_score(y_train, gnb.predict(X_train_scaled))*100)\n",
    "    print('Validation Accuracy : ', metrics.accuracy_score(y_test, gnb.predict(X_test_scaled))*100)\n",
    "    \n",
    "    class_labels = y.unique()\n",
    "    cm = metrics.confusion_matrix(y_test, gnb.predict(X_test_scaled))\n",
    "    matrices[name] = cm\n",
    "    \n",
    "    class_labels_str = [str(label) for label in class_labels]\n",
    "    cr = metrics.classification_report(y_test, gnb.predict(X_test_scaled), target_names=class_labels_str)\n",
    "    print(\"Classification Report:\")\n",
    "    print(cr)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
