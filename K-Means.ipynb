{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iOZcbQFZg8QR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading and scalling the data\n",
        "\n",
        "Testing different datasets - clean with all 79 columns, and final with two different selections of 15 most important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_c = pd.read_parquet('./Local/2017_Clean/Combined.parquet')\n",
        "data_f1 = pd.read_parquet('./Local/2017_Final/Combined_1.parquet')\n",
        "data_f2 = pd.read_parquet('./Local/2017_Final/Combined_2.parquet')\n",
        "\n",
        "data_c = data_c.drop(columns=[' Label'])\n",
        "data_f1 = data_f1.drop(columns=['Label'])\n",
        "data_f2 = data_f2.drop(columns=['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reducing the dimensions using PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = {'Clean data': data_c, 'Final data 1': data_f1, 'Final data 2': data_f2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Clean data ---\n",
            "Explained variation per principal component (PC): [0.62860641 0.11010856]\n",
            "Cumulative variance explained by 2 principal components: 73.87%\n",
            "\n",
            "--- Final data 1 ---\n",
            "Explained variation per principal component (PC): [0.79193891 0.20800771]\n",
            "Cumulative variance explained by 2 principal components: 99.99%\n",
            "\n",
            "--- Final data 2 ---\n",
            "Explained variation per principal component (PC): [0.79197042 0.20801583]\n",
            "Cumulative variance explained by 2 principal components: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, data in datasets.items():\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(data)\n",
        "    \n",
        "    print(f'--- {name} ---')\n",
        "    print('Explained variation per principal component (PC): {}'.format(pca.explained_variance_ratio_))\n",
        "    print('Cumulative variance explained by 2 principal components: {:.2%}\\n'.format(np.sum(pca.explained_variance_ratio_)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Clean data ---\n",
            "Most important features:\n",
            "\n",
            "PC 1:\n",
            "  Flow Duration    0.435160\n",
            " Flow IAT Max     0.313612\n",
            "Fwd IAT Total     0.434277\n",
            " Fwd IAT Max      0.314557\n",
            "Idle Mean         0.301654\n",
            " Idle Max         0.312721\n",
            "Name: PC_1, dtype: float64\n",
            "PC 2:\n",
            "  Flow Duration    0.309949\n",
            "Fwd IAT Total     0.306129\n",
            "Bwd IAT Total     0.624901\n",
            "Name: PC_2, dtype: float64\n",
            "\n",
            "\n",
            "--- Final data 1 ---\n",
            "Most important features:\n",
            "\n",
            "PC 1:\n",
            " Total Length of Bwd Packets    0.707105\n",
            "Subflow Bwd Bytes              0.707095\n",
            "Name: PC_1, dtype: float64\n",
            "PC 2:\n",
            " Packet Length Variance    0.99999\n",
            "Name: PC_2, dtype: float64\n",
            "\n",
            "\n",
            "--- Final data 2 ---\n",
            "Most important features:\n",
            "\n",
            "PC 1:\n",
            " Total Length of Bwd Packets    0.707105\n",
            "Subflow Bwd Bytes              0.707095\n",
            "Name: PC_1, dtype: float64\n",
            "PC 2:\n",
            " Packet Length Variance    0.999991\n",
            "Name: PC_2, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, data in datasets.items():\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(data)\n",
        "    data_pca = pd.DataFrame(abs(pca.components_), columns=data.columns, index=['PC_1', 'PC_2'])\n",
        "\n",
        "    print(f'--- {name} ---')\n",
        "    print('Most important features:\\n')\n",
        "    print('PC 1:\\n', (data_pca[data_pca > 0.3].iloc[0]).dropna())   \n",
        "    print('PC 2:\\n', (data_pca[data_pca > 0.3].iloc[1]).dropna())\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter tuning using the silhouette method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m kmeans_model \u001b[38;5;241m=\u001b[39m KMeans(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp)\u001b[38;5;241m.\u001b[39mfit(data_f1)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#kmeans_model = KMeans(**p).fit(data_f2)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m current_score \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmeans_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m silhouette_scores\u001b[38;5;241m.\u001b[39mappend(current_score)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter:\u001b[39m\u001b[38;5;124m'\u001b[39m, p, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m, current_score)\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:141\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:305\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    301\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    302\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    303\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    304\u001b[0m )\n\u001b[0;32m--> 305\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    307\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2181\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2180\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m D_chunk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 2181\u001b[0m     D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
            "File \u001b[0;32m/run/media/arzaca/Maxtor/Network-Anomaly-Detection/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:182\u001b[0m, in \u001b[0;36m_silhouette_reduce\u001b[0;34m(D_chunk, start, labels, label_freqs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         sample_weights \u001b[38;5;241m=\u001b[39m D_chunk[i]\n\u001b[1;32m    181\u001b[0m         sample_labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[0;32m--> 182\u001b[0m         cluster_distances[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_freqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# intra_index selects intra-cluster distances within cluster_distances\u001b[39;00m\n\u001b[1;32m    187\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m n_chunk_samples\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 2 for Benign/Attack recognition\n",
        "# 15 for Attack classification (14 Attack types + Benign)\n",
        "parameters = [2]\n",
        "parameter_grid = ParameterGrid({'n_clusters': parameters})\n",
        "\n",
        "best_score = -1\n",
        "best_grid = None\n",
        "silhouette_scores = []\n",
        "\n",
        "for p in parameter_grid:\n",
        "    #kmeans_model = KMeans(**p).fit(data_c)\n",
        "    kmeans_model = KMeans(**p).fit(data_f1)\n",
        "    #kmeans_model = KMeans(**p).fit(data_f2)\n",
        "\n",
        "    current_score = silhouette_score(data, kmeans_model.labels_)\n",
        "    silhouette_scores.append(current_score)\n",
        "    print('Parameter:', p, 'Score', current_score)\n",
        "    if current_score > best_score:\n",
        "        best_score = current_score\n",
        "        best_grid = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(range(len(silhouette_scores)), silhouette_scores, align='center', color='#722f59', width=0.5)\n",
        "plt.xticks(range(len(silhouette_scores)), parameters)\n",
        "plt.title('Silhouette Score', fontweight='bold')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
